train:
  train_teacher:
   epoch: 20
   lr: 0.001
   log:
     path: 'output/log/svhn_teacher.log'
     log_every: 10
   save_every: 5
   checkpoint_path: 'output/checkpoints/svhn_teacher'
   sample_path: 'output/images/svhn'

  train_score:
   # caution, score dataloader is implemented by generator,
   # once the last sample is enumerated, the training comes to an end
   # setting epoch here is useless, change the datasize to control training
   batch_size: 128
   epoch: 1
   datasize: 800000
   lr: 0.001
   log:
     path: 'output/log/svhn_score.log'
     log_every: 20
   save_every: 5
   checkpoint_path: 'output/checkpoints/svhn_score'

  train_students:
   epoch: 20
   lr: 0.001
   log:
     path: 'output/log/svhn_student.log'
     log_every: 10
   save_every: 5
   checkpoint_path: 'output/checkpoints/svhn_student'
   sample_path: 'output/images/svhn_student'

  teacher_path: 'output/checkpoints/svhn_teacher19.pt'
  score_path: 'output/checkpoints/svhn_score.pt'
  student_path: 'output/checkpoints/svhn_student19.pt'
  batch_size: 128

  student:
    src: [1,2,3,4]
    dst: [1,2,3,4,5,6,7,8]


GA:
  fit_func:
    data_size: 4000
    batch_size: 40
    lr: 0.001
    iter_limit: 200

  instance:
    num_generations: 32
    num_genes: 8
    num_parents_mating: 8
    sol_per_pop: 10

    init_range_low: 0
    init_range_high: 1

    parent_selection_type: 'sss'
    keep_parents: 4
    crossover_type: 'uniform'

    mutation_type: 'scramble'
    # mutation_percent_genes: 2
    mutation_num_genes: 2
  upper_bound: 0.0000000001
  fitness_fig_path: 'output/images/fitness/svhn'


data:
  name: 'SVHN'
  root: 'data/SVHN'
  transform: 'MNIST_train_trans'
  download: True



model:
  pooling_kernel: [2, 2]
  encoder_output_size: 7
  color_channels: 1
  num_classes: 10
optim:
  lr: 0.001


