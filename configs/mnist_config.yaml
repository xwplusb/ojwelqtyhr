train:
  # train_teacher:
  #   epoch: 10
  #   lr: 0.001
  #   log:
  #     path: 'output/log/mnist_teacher.log'
  #     log_every: 10
  #   save_every: 2
  #   checkpoint_path: 'output/checkpoints/mnist_teacher'
  #   sample_path: 'output/images/mnist'
  teacher_path: 'output/checkpoints/mnist_teacher1.pt'

  train_score:
    iteration: 100
    lr: 0.001
    log:
      path: 'output/log/mnist_score.log'
      log_every: 20
    save_every: 2
    checkpoint_path: 'output/checkpoints/mnist_score'
  batch_size: 128


data:
  name: 'MNIST'
  root: 'data'
  transform: 'MNIST_train_trans'
  download: True


model:
  pooling_kernel: [2, 2]
  encoder_output_size: 7
  color_channels: 1
  num_classes: 10
optim:
  lr: 0.001


